{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sports Image Dataset Exploration\n",
    "\n",
    "## EE4745 Neural Networks Final Project\n",
    "\n",
    "This notebook provides comprehensive exploration and analysis of the sports image dataset used for classification tasks.\n",
    "\n",
    "### Objectives:\n",
    "- Dataset overview and structure analysis\n",
    "- Class distribution analysis\n",
    "- Sample image visualization\n",
    "- Data augmentation demonstration\n",
    "- Dataset validation and quality assessment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "Import necessary libraries and set up the environment for data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from collections import defaultdict, Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import custom modules\n",
    "from dataset.sports_dataset import SportsDataset, get_dataloaders\n",
    "from training.utils import set_seed\n",
    "\n",
    "# Set style and seed for reproducibility\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "set_seed(42)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 150\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Environment setup complete!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device available: {'GPU' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Overview\n",
    "\n",
    "Let's start by examining the basic structure of our sports image dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configuration\n",
    "DATA_DIR = '../data'\n",
    "IMAGE_SIZE = 32  # Start with 32x32 images\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Check if data directory exists\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    print(f\"Data directory {DATA_DIR} not found!\")\n",
    "    print(\"Please ensure the data symlink is properly configured.\")\n",
    "else:\n",
    "    print(f\"Data directory found: {DATA_DIR}\")\n",
    "    \n",
    "    # List the splits\n",
    "    splits = [d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))]\n",
    "    print(f\"Available splits: {splits}\")\n",
    "    \n",
    "    # List classes from the training split\n",
    "    train_dir = os.path.join(DATA_DIR, 'train')\n",
    "    if os.path.exists(train_dir):\n",
    "        classes = sorted([d for d in os.listdir(train_dir) \n",
    "                         if os.path.isdir(os.path.join(train_dir, d))])\n",
    "        print(f\"\\nClasses in dataset ({len(classes)}):\")\n",
    "        for i, cls in enumerate(classes):\n",
    "            print(f\"  {i}: {cls}\")\n",
    "    else:\n",
    "        print(f\"Training directory not found: {train_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Statistics\n",
    "\n",
    "Let's analyze the size and distribution of our dataset across different splits and classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset_structure(data_dir):\n",
    "    \"\"\"Analyze the structure and statistics of the dataset\"\"\"\n",
    "    \n",
    "    stats = {\n",
    "        'splits': {},\n",
    "        'total_images': 0,\n",
    "        'classes': SportsDataset.CLASSES\n",
    "    }\n",
    "    \n",
    "    # Analyze each split\n",
    "    for split in ['train', 'valid']:\n",
    "        split_dir = os.path.join(data_dir, split)\n",
    "        if not os.path.exists(split_dir):\n",
    "            continue\n",
    "            \n",
    "        split_stats = {\n",
    "            'total_images': 0,\n",
    "            'class_distribution': {},\n",
    "            'image_sizes': [],\n",
    "            'file_formats': Counter()\n",
    "        }\n",
    "        \n",
    "        # Analyze each class\n",
    "        for class_name in SportsDataset.CLASSES:\n",
    "            class_dir = os.path.join(split_dir, class_name)\n",
    "            if not os.path.exists(class_dir):\n",
    "                split_stats['class_distribution'][class_name] = 0\n",
    "                continue\n",
    "                \n",
    "            # Count images and analyze properties\n",
    "            images = [f for f in os.listdir(class_dir) \n",
    "                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            \n",
    "            split_stats['class_distribution'][class_name] = len(images)\n",
    "            split_stats['total_images'] += len(images)\n",
    "            \n",
    "            # Sample a few images to check properties\n",
    "            sample_images = images[:min(5, len(images))]\n",
    "            for img_name in sample_images:\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                try:\n",
    "                    with Image.open(img_path) as img:\n",
    "                        split_stats['image_sizes'].append(img.size)\n",
    "                        split_stats['file_formats'][img.format] += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {img_path}: {e}\")\n",
    "        \n",
    "        stats['splits'][split] = split_stats\n",
    "        stats['total_images'] += split_stats['total_images']\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Analyze dataset\n",
    "print(\"Analyzing dataset structure...\")\n",
    "dataset_stats = analyze_dataset_structure(DATA_DIR)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATASET STATISTICS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Total images: {dataset_stats['total_images']:,}\")\n",
    "print(f\"Number of classes: {len(dataset_stats['classes'])}\")\n",
    "print(f\"Classes: {', '.join(dataset_stats['classes'])}\")\n",
    "\n",
    "for split_name, split_data in dataset_stats['splits'].items():\n",
    "    print(f\"\\n{split_name.upper()} SET:\")\n",
    "    print(f\"  Total images: {split_data['total_images']:,}\")\n",
    "    print(f\"  Images per class:\")\n",
    "    for class_name, count in split_data['class_distribution'].items():\n",
    "        percentage = (count / split_data['total_images']) * 100 if split_data['total_images'] > 0 else 0\n",
    "        print(f\"    {class_name:12}: {count:4d} ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Image format statistics\n",
    "    if split_data['file_formats']:\n",
    "        print(f\"  File formats: {dict(split_data['file_formats'])}\")\n",
    "    \n",
    "    # Image size statistics\n",
    "    if split_data['image_sizes']:\n",
    "        sizes = split_data['image_sizes']\n",
    "        unique_sizes = list(set(sizes))\n",
    "        print(f\"  Sample image sizes: {unique_sizes[:5]}{'...' if len(unique_sizes) > 5 else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Class Distribution Analysis\n",
    "\n",
    "Visualize the distribution of images across different sports classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations for class distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Dataset Class Distribution Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Prepare data for visualization\n",
    "train_dist = dataset_stats['splits'].get('train', {}).get('class_distribution', {})\n",
    "valid_dist = dataset_stats['splits'].get('valid', {}).get('class_distribution', {})\n",
    "\n",
    "classes = list(train_dist.keys())\n",
    "train_counts = list(train_dist.values())\n",
    "valid_counts = list(valid_dist.values())\n",
    "\n",
    "# 1. Training set distribution (bar plot)\n",
    "axes[0, 0].bar(range(len(classes)), train_counts, color=sns.color_palette('husl', len(classes)))\n",
    "axes[0, 0].set_title('Training Set - Class Distribution', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Sports Classes')\n",
    "axes[0, 0].set_ylabel('Number of Images')\n",
    "axes[0, 0].set_xticks(range(len(classes)))\n",
    "axes[0, 0].set_xticklabels(classes, rotation=45, ha='right')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(train_counts):\n",
    "    axes[0, 0].text(i, v + max(train_counts)*0.01, str(v), ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 2. Validation set distribution (bar plot)\n",
    "axes[0, 1].bar(range(len(classes)), valid_counts, color=sns.color_palette('husl', len(classes)))\n",
    "axes[0, 1].set_title('Validation Set - Class Distribution', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Sports Classes')\n",
    "axes[0, 1].set_ylabel('Number of Images')\n",
    "axes[0, 1].set_xticks(range(len(classes)))\n",
    "axes[0, 1].set_xticklabels(classes, rotation=45, ha='right')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(valid_counts):\n",
    "    axes[0, 1].text(i, v + max(valid_counts)*0.01, str(v), ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 3. Combined comparison (grouped bar plot)\n",
    "x = np.arange(len(classes))\n",
    "width = 0.35\n",
    "\n",
    "axes[1, 0].bar(x - width/2, train_counts, width, label='Training', alpha=0.8)\n",
    "axes[1, 0].bar(x + width/2, valid_counts, width, label='Validation', alpha=0.8)\n",
    "axes[1, 0].set_title('Training vs Validation - Class Distribution', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Sports Classes')\n",
    "axes[1, 0].set_ylabel('Number of Images')\n",
    "axes[1, 0].set_xticks(x)\n",
    "axes[1, 0].set_xticklabels(classes, rotation=45, ha='right')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Distribution pie chart (training set)\n",
    "axes[1, 1].pie(train_counts, labels=classes, autopct='%1.1f%%', startangle=90)\n",
    "axes[1, 1].set_title('Training Set - Class Distribution (Pie Chart)', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print class balance analysis\n",
    "print(\"\\nCLASS BALANCE ANALYSIS:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "if train_counts:\n",
    "    train_mean = np.mean(train_counts)\n",
    "    train_std = np.std(train_counts)\n",
    "    train_cv = train_std / train_mean if train_mean > 0 else 0\n",
    "    \n",
    "    print(f\"Training set:\")\n",
    "    print(f\"  Mean images per class: {train_mean:.1f}\")\n",
    "    print(f\"  Standard deviation: {train_std:.1f}\")\n",
    "    print(f\"  Coefficient of variation: {train_cv:.3f}\")\n",
    "    print(f\"  Balance ratio (min/max): {min(train_counts)/max(train_counts):.3f}\")\n",
    "\n",
    "if valid_counts:\n",
    "    valid_mean = np.mean(valid_counts)\n",
    "    valid_std = np.std(valid_counts)\n",
    "    valid_cv = valid_std / valid_mean if valid_mean > 0 else 0\n",
    "    \n",
    "    print(f\"\\nValidation set:\")\n",
    "    print(f\"  Mean images per class: {valid_mean:.1f}\")\n",
    "    print(f\"  Standard deviation: {valid_std:.1f}\")\n",
    "    print(f\"  Coefficient of variation: {valid_cv:.3f}\")\n",
    "    print(f\"  Balance ratio (min/max): {min(valid_counts)/max(valid_counts):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sample Image Visualization\n",
    "\n",
    "Display representative images from each sports class to understand the visual characteristics of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample_images(data_dir, classes, samples_per_class=3, image_size=(64, 64)):\n",
    "    \"\"\"Display sample images from each class\"\"\"\n",
    "    \n",
    "    num_classes = len(classes)\n",
    "    fig, axes = plt.subplots(num_classes, samples_per_class, \n",
    "                            figsize=(samples_per_class * 3, num_classes * 2.5))\n",
    "    \n",
    "    fig.suptitle('Sample Images from Each Sports Class', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    if num_classes == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for class_idx, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(data_dir, 'train', class_name)\n",
    "        \n",
    "        if not os.path.exists(class_dir):\n",
    "            continue\n",
    "            \n",
    "        # Get image files\n",
    "        images = [f for f in os.listdir(class_dir) \n",
    "                 if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        \n",
    "        # Sample random images\n",
    "        np.random.seed(42)  # For reproducible sampling\n",
    "        sampled_images = np.random.choice(images, \n",
    "                                        min(samples_per_class, len(images)), \n",
    "                                        replace=False)\n",
    "        \n",
    "        for img_idx, img_name in enumerate(sampled_images):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            \n",
    "            try:\n",
    "                # Load and display image\n",
    "                with Image.open(img_path) as img:\n",
    "                    # Convert to RGB if necessary\n",
    "                    if img.mode != 'RGB':\n",
    "                        img = img.convert('RGB')\n",
    "                    \n",
    "                    # Resize for consistent display\n",
    "                    img_resized = img.resize(image_size, Image.Resampling.LANCZOS)\n",
    "                    \n",
    "                    # Display\n",
    "                    if samples_per_class == 1:\n",
    "                        ax = axes[class_idx]\n",
    "                    else:\n",
    "                        ax = axes[class_idx, img_idx]\n",
    "                    \n",
    "                    ax.imshow(img_resized)\n",
    "                    ax.axis('off')\n",
    "                    \n",
    "                    # Add title with class name and image info\n",
    "                    title = f'{class_name}'\n",
    "                    if img_idx == 0:  # Only add class name to first image\n",
    "                        title += f'\\n({img.size[0]}x{img.size[1]})'\n",
    "                    else:\n",
    "                        title = f'({img.size[0]}x{img.size[1]})'\n",
    "                    \n",
    "                    ax.set_title(title, fontsize=10)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "                # Display placeholder\n",
    "                if samples_per_class == 1:\n",
    "                    ax = axes[class_idx]\n",
    "                else:\n",
    "                    ax = axes[class_idx, img_idx]\n",
    "                \n",
    "                ax.text(0.5, 0.5, 'Error\\nLoading\\nImage', \n",
    "                       ha='center', va='center', transform=ax.transAxes)\n",
    "                ax.set_title(f'{class_name} (Error)', fontsize=10)\n",
    "                ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display sample images\n",
    "print(\"Displaying sample images from each class...\")\n",
    "display_sample_images(DATA_DIR, dataset_stats['classes'], samples_per_class=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Properties Analysis\n",
    "\n",
    "Let's analyze the properties of images in our dataset such as dimensions, aspect ratios, and color characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_properties(data_dir, classes, max_samples=50):\n",
    "    \"\"\"Analyze properties of images in the dataset\"\"\"\n",
    "    \n",
    "    properties = {\n",
    "        'dimensions': [],\n",
    "        'aspect_ratios': [],\n",
    "        'file_sizes': [],\n",
    "        'mean_colors': [],\n",
    "        'formats': Counter()\n",
    "    }\n",
    "    \n",
    "    print(f\"Analyzing image properties (sampling up to {max_samples} images per class)...\")\n",
    "    \n",
    "    for class_name in classes:\n",
    "        class_dir = os.path.join(data_dir, 'train', class_name)\n",
    "        \n",
    "        if not os.path.exists(class_dir):\n",
    "            continue\n",
    "            \n",
    "        images = [f for f in os.listdir(class_dir) \n",
    "                 if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        \n",
    "        # Sample images for analysis\n",
    "        np.random.seed(42)\n",
    "        sampled_images = np.random.choice(images, \n",
    "                                        min(max_samples, len(images)), \n",
    "                                        replace=False)\n",
    "        \n",
    "        for img_name in sampled_images:\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            \n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    # Basic properties\n",
    "                    properties['dimensions'].append(img.size)\n",
    "                    properties['aspect_ratios'].append(img.size[0] / img.size[1])\n",
    "                    properties['file_sizes'].append(os.path.getsize(img_path))\n",
    "                    properties['formats'][img.format] += 1\n",
    "                    \n",
    "                    # Color analysis (convert to RGB first)\n",
    "                    if img.mode != 'RGB':\n",
    "                        img = img.convert('RGB')\n",
    "                    \n",
    "                    # Calculate mean color\n",
    "                    img_array = np.array(img)\n",
    "                    mean_color = img_array.mean(axis=(0, 1))\n",
    "                    properties['mean_colors'].append(mean_color)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error analyzing {img_path}: {e}\")\n",
    "    \n",
    "    return properties\n",
    "\n",
    "# Analyze image properties\n",
    "img_properties = analyze_image_properties(DATA_DIR, dataset_stats['classes'])\n",
    "\n",
    "# Visualize the analysis\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Image Properties Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Image dimensions scatter plot\n",
    "if img_properties['dimensions']:\n",
    "    widths, heights = zip(*img_properties['dimensions'])\n",
    "    \n",
    "    axes[0, 0].scatter(widths, heights, alpha=0.6, s=20)\n",
    "    axes[0, 0].set_title('Image Dimensions Distribution', fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Width (pixels)')\n",
    "    axes[0, 0].set_ylabel('Height (pixels)')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add diagonal line for square images\n",
    "    max_dim = max(max(widths), max(heights))\n",
    "    axes[0, 0].plot([0, max_dim], [0, max_dim], 'r--', alpha=0.5, label='Square')\n",
    "    axes[0, 0].legend()\n",
    "\n",
    "# 2. Aspect ratio histogram\n",
    "if img_properties['aspect_ratios']:\n",
    "    axes[0, 1].hist(img_properties['aspect_ratios'], bins=30, alpha=0.7, edgecolor='black')\n",
    "    axes[0, 1].axvline(1.0, color='red', linestyle='--', label='Square (1:1)')\n",
    "    axes[0, 1].set_title('Aspect Ratio Distribution', fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Aspect Ratio (Width/Height)')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. File size distribution\n",
    "if img_properties['file_sizes']:\n",
    "    file_sizes_kb = [size / 1024 for size in img_properties['file_sizes']]  # Convert to KB\n",
    "    axes[0, 2].hist(file_sizes_kb, bins=30, alpha=0.7, edgecolor='black')\n",
    "    axes[0, 2].set_title('File Size Distribution', fontweight='bold')\n",
    "    axes[0, 2].set_xlabel('File Size (KB)')\n",
    "    axes[0, 2].set_ylabel('Frequency')\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Mean RGB color distribution\n",
    "if img_properties['mean_colors']:\n",
    "    mean_colors = np.array(img_properties['mean_colors'])\n",
    "    \n",
    "    colors = ['red', 'green', 'blue']\n",
    "    labels = ['Red', 'Green', 'Blue']\n",
    "    \n",
    "    for i, (color, label) in enumerate(zip(colors, labels)):\n",
    "        axes[1, 0].hist(mean_colors[:, i], bins=20, alpha=0.7, \n",
    "                       color=color, label=label, edgecolor='black')\n",
    "    \n",
    "    axes[1, 0].set_title('Mean RGB Channel Distribution', fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Mean Pixel Value (0-255)')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Format distribution pie chart\n",
    "if img_properties['formats']:\n",
    "    formats = list(img_properties['formats'].keys())\n",
    "    counts = list(img_properties['formats'].values())\n",
    "    \n",
    "    axes[1, 1].pie(counts, labels=formats, autopct='%1.1f%%', startangle=90)\n",
    "    axes[1, 1].set_title('File Format Distribution', fontweight='bold')\n",
    "\n",
    "# 6. Summary statistics\n",
    "axes[1, 2].axis('off')\n",
    "summary_text = \"Dataset Statistics Summary\\n\" + \"=\"*25 + \"\\n\\n\"\n",
    "\n",
    "if img_properties['dimensions']:\n",
    "    widths, heights = zip(*img_properties['dimensions'])\n",
    "    summary_text += f\"Dimensions:\\n\"\n",
    "    summary_text += f\"  Width: {np.mean(widths):.1f}¬±{np.std(widths):.1f}px\\n\"\n",
    "    summary_text += f\"  Height: {np.mean(heights):.1f}¬±{np.std(heights):.1f}px\\n\\n\"\n",
    "\n",
    "if img_properties['aspect_ratios']:\n",
    "    summary_text += f\"Aspect Ratio: {np.mean(img_properties['aspect_ratios']):.2f}¬±{np.std(img_properties['aspect_ratios']):.2f}\\n\\n\"\n",
    "\n",
    "if img_properties['file_sizes']:\n",
    "    sizes_kb = [s/1024 for s in img_properties['file_sizes']]\n",
    "    summary_text += f\"File Size: {np.mean(sizes_kb):.1f}¬±{np.std(sizes_kb):.1f} KB\\n\\n\"\n",
    "\n",
    "if img_properties['mean_colors']:\n",
    "    mean_colors = np.array(img_properties['mean_colors'])\n",
    "    summary_text += f\"Mean RGB:\\n\"\n",
    "    summary_text += f\"  R: {np.mean(mean_colors[:, 0]):.1f}¬±{np.std(mean_colors[:, 0]):.1f}\\n\"\n",
    "    summary_text += f\"  G: {np.mean(mean_colors[:, 1]):.1f}¬±{np.std(mean_colors[:, 1]):.1f}\\n\"\n",
    "    summary_text += f\"  B: {np.mean(mean_colors[:, 2]):.1f}¬±{np.std(mean_colors[:, 2]):.1f}\\n\"\n",
    "\n",
    "axes[1, 2].text(0.1, 0.9, summary_text, transform=axes[1, 2].transAxes, \n",
    "               fontsize=11, verticalalignment='top', fontfamily='monospace',\n",
    "               bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAnalyzed {len(img_properties['dimensions'])} images total.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Augmentation Demonstration\n",
    "\n",
    "Explore the data augmentation techniques used in training and their effects on the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_augmentations(data_dir, class_name='basketball', image_size=64):\n",
    "    \"\"\"Demonstrate various data augmentation techniques\"\"\"\n",
    "    \n",
    "    # Load a sample image\n",
    "    class_dir = os.path.join(data_dir, 'train', class_name)\n",
    "    images = [f for f in os.listdir(class_dir) \n",
    "             if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    if not images:\n",
    "        print(f\"No images found in {class_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Select a sample image\n",
    "    sample_image_path = os.path.join(class_dir, images[0])\n",
    "    original_image = Image.open(sample_image_path).convert('RGB')\n",
    "    \n",
    "    # Define different augmentation transforms\n",
    "    augmentations = {\n",
    "        'Original': transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor()\n",
    "        ]),\n",
    "        'Horizontal Flip': transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.RandomHorizontalFlip(p=1.0),\n",
    "            transforms.ToTensor()\n",
    "        ]),\n",
    "        'Rotation (¬±15¬∞)': transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ToTensor()\n",
    "        ]),\n",
    "        'Color Jitter': transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "            transforms.ToTensor()\n",
    "        ]),\n",
    "        'Random Crop': transforms.Compose([\n",
    "            transforms.Resize((int(image_size * 1.2), int(image_size * 1.2))),\n",
    "            transforms.RandomCrop(image_size),\n",
    "            transforms.ToTensor()\n",
    "        ]),\n",
    "        'Combined': transforms.Compose([\n",
    "            transforms.Resize((int(image_size * 1.2), int(image_size * 1.2))),\n",
    "            transforms.RandomCrop(image_size),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=10),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    }\n",
    "    \n",
    "    # Create visualization\n",
    "    num_augs = len(augmentations)\n",
    "    num_samples = 3  # Show 3 samples of each augmentation\n",
    "    \n",
    "    fig, axes = plt.subplots(num_augs, num_samples, figsize=(num_samples * 3, num_augs * 2.5))\n",
    "    fig.suptitle(f'Data Augmentation Examples\\nOriginal Image: {class_name}', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for row, (aug_name, transform) in enumerate(augmentations.items()):\n",
    "        for col in range(num_samples):\n",
    "            # Apply transformation\n",
    "            torch.manual_seed(42 + col)  # For reproducible results\n",
    "            transformed = transform(original_image)\n",
    "            \n",
    "            # Convert tensor back to displayable format\n",
    "            if transformed.shape[0] == 3:  # RGB channels\n",
    "                img_display = transformed.permute(1, 2, 0).numpy()\n",
    "                img_display = np.clip(img_display, 0, 1)\n",
    "            else:\n",
    "                img_display = transformed.squeeze().numpy()\n",
    "            \n",
    "            # Display\n",
    "            ax = axes[row, col] if num_augs > 1 else axes[col]\n",
    "            ax.imshow(img_display)\n",
    "            ax.axis('off')\n",
    "            \n",
    "            # Add title only to first column\n",
    "            if col == 0:\n",
    "                ax.set_title(aug_name, fontweight='bold', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Demonstrate augmentations\n",
    "print(\"Demonstrating data augmentation techniques...\")\n",
    "demonstrate_augmentations(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training vs Validation Transforms Comparison\n",
    "\n",
    "Compare the actual transforms used in the SportsDataset for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load actual datasets to see the transforms in action\ntrain_dataset = SportsDataset(root_dir=DATA_DIR, split='train', image_size=IMAGE_SIZE, augment=True)\nval_dataset = SportsDataset(root_dir=DATA_DIR, split='valid', image_size=IMAGE_SIZE, augment=False)\n\nprint(\"Training Dataset Transform:\")\nprint(train_dataset.transform)\n\nprint(\"\\nValidation Dataset Transform:\")\nprint(val_dataset.transform)\n\n# Show examples of actual training transforms\ndef show_training_samples(dataset, num_samples=6, title=\"Training Dataset Samples\"):\n    \"\"\"Show samples from dataset with applied transforms\"\"\"\n    \n    fig, axes = plt.subplots(2, num_samples//2, figsize=(15, 6))\n    fig.suptitle(title, fontsize=14, fontweight='bold')\n    \n    # Set seed for reproducible sampling\n    torch.manual_seed(42)\n    \n    for i in range(num_samples):\n        # Get a random sample\n        idx = torch.randint(0, len(dataset), (1,)).item()\n        image, label = dataset[idx]\n        class_name = dataset.CLASSES[label]\n        \n        # Denormalize image for display\n        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n        denormalized = image * std + mean\n        denormalized = torch.clamp(denormalized, 0, 1)\n        \n        # Display\n        row, col = i // 3, i % 3\n        ax = axes[row, col]\n        ax.imshow(denormalized.permute(1, 2, 0))\n        ax.set_title(f'{class_name}', fontsize=10)\n        ax.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Show training and validation samples\nshow_training_samples(train_dataset, title=\"Training Dataset Samples (with augmentation)\")\nshow_training_samples(val_dataset, title=\"Validation Dataset Samples (no augmentation)\")\n\n# Dataset size information\nprint(f\"\\nDataset Sizes:\")\nprint(f\"Training set: {len(train_dataset):,} images\")\nprint(f\"Validation set: {len(val_dataset):,} images\")\nprint(f\"Total: {len(train_dataset) + len(val_dataset):,} images\")\n\n# Class distribution from actual dataset\ntrain_dist = train_dataset.get_class_distribution()\nval_dist = val_dataset.get_class_distribution()\n\nprint(f\"\\nClass distribution comparison:\")\nprint(f\"{'Class':<12} {'Train':<8} {'Valid':<8} {'Ratio':<8}\")\nprint(\"-\" * 40)\nfor class_name in dataset_stats['classes']:\n    train_count = train_dist.get(class_name, 0)\n    val_count = val_dist.get(class_name, 0)\n    ratio = train_count / val_count if val_count > 0 else float('inf')\n    print(f\"{class_name:<12} {train_count:<8} {val_count:<8} {ratio:<8.1f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dataset Validation and Quality Assessment\n",
    "\n",
    "Perform quality checks on the dataset to identify potential issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_dataset_quality(data_dir, classes, sample_size=100):\n",
    "    \"\"\"Validate dataset quality and identify potential issues\"\"\"\n",
    "    \n",
    "    print(\"Performing dataset quality validation...\")\n",
    "    \n",
    "    issues = {\n",
    "        'corrupted_images': [],\n",
    "        'extremely_small_images': [],\n",
    "        'extremely_large_images': [],\n",
    "        'unusual_aspect_ratios': [],\n",
    "        'grayscale_images': [],\n",
    "        'very_dark_images': [],\n",
    "        'very_bright_images': []\n",
    "    }\n",
    "    \n",
    "    processed_count = 0\n",
    "    total_images = 0\n",
    "    \n",
    "    for split in ['train', 'valid']:\n",
    "        for class_name in classes:\n",
    "            class_dir = os.path.join(data_dir, split, class_name)\n",
    "            \n",
    "            if not os.path.exists(class_dir):\n",
    "                continue\n",
    "                \n",
    "            images = [f for f in os.listdir(class_dir) \n",
    "                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            \n",
    "            total_images += len(images)\n",
    "            \n",
    "            # Sample images for quality check\n",
    "            np.random.seed(42)\n",
    "            sampled_images = np.random.choice(images, \n",
    "                                            min(sample_size, len(images)), \n",
    "                                            replace=False)\n",
    "            \n",
    "            for img_name in sampled_images:\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                \n",
    "                try:\n",
    "                    with Image.open(img_path) as img:\n",
    "                        # Basic corruption check\n",
    "                        img.verify()  # Verify image integrity\n",
    "                        \n",
    "                        # Reopen for analysis (verify closes the file)\n",
    "                        with Image.open(img_path) as img:\n",
    "                            width, height = img.size\n",
    "                            aspect_ratio = width / height\n",
    "                            \n",
    "                            # Check for extremely small images\n",
    "                            if width < 32 or height < 32:\n",
    "                                issues['extremely_small_images'].append(\n",
    "                                    (img_path, f\"{width}x{height}\")\n",
    "                                )\n",
    "                            \n",
    "                            # Check for extremely large images\n",
    "                            if width > 2000 or height > 2000:\n",
    "                                issues['extremely_large_images'].append(\n",
    "                                    (img_path, f\"{width}x{height}\")\n",
    "                                )\n",
    "                            \n",
    "                            # Check for unusual aspect ratios\n",
    "                            if aspect_ratio < 0.3 or aspect_ratio > 3.0:\n",
    "                                issues['unusual_aspect_ratios'].append(\n",
    "                                    (img_path, f\"{aspect_ratio:.2f}\")\n",
    "                                )\n",
    "                            \n",
    "                            # Convert to RGB for color analysis\n",
    "                            if img.mode != 'RGB':\n",
    "                                if img.mode in ['L', 'LA']:  # Grayscale\n",
    "                                    issues['grayscale_images'].append(img_path)\n",
    "                                img = img.convert('RGB')\n",
    "                            \n",
    "                            # Analyze brightness\n",
    "                            img_array = np.array(img)\n",
    "                            mean_brightness = img_array.mean()\n",
    "                            \n",
    "                            if mean_brightness < 30:  # Very dark\n",
    "                                issues['very_dark_images'].append(\n",
    "                                    (img_path, f\"brightness: {mean_brightness:.1f}\")\n",
    "                                )\n",
    "                            elif mean_brightness > 225:  # Very bright\n",
    "                                issues['very_bright_images'].append(\n",
    "                                    (img_path, f\"brightness: {mean_brightness:.1f}\")\n",
    "                                )\n",
    "                            \n",
    "                            processed_count += 1\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    issues['corrupted_images'].append((img_path, str(e)))\n",
    "    \n",
    "    return issues, processed_count, total_images\n",
    "\n",
    "# Perform quality validation\n",
    "quality_issues, processed, total = validate_dataset_quality(DATA_DIR, dataset_stats['classes'])\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DATASET QUALITY ASSESSMENT RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\"\\nProcessed {processed:,} images out of {total:,} total images\")\n",
    "print(f\"Sample rate: {processed/total*100:.1f}%\")\n",
    "\n",
    "print(\"\\nQuality Issues Found:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for issue_type, issues in quality_issues.items():\n",
    "    issue_name = issue_type.replace('_', ' ').title()\n",
    "    print(f\"{issue_name}: {len(issues)}\")\n",
    "    \n",
    "    if issues and len(issues) <= 5:  # Show details for small number of issues\n",
    "        for item in issues:\n",
    "            if isinstance(item, tuple):\n",
    "                print(f\"  - {item[0]} ({item[1]})\")\n",
    "            else:\n",
    "                print(f\"  - {item}\")\n",
    "    elif issues:\n",
    "        print(f\"  (showing first 3 out of {len(issues)})\")\n",
    "        for item in issues[:3]:\n",
    "            if isinstance(item, tuple):\n",
    "                print(f\"  - {item[0]} ({item[1]})\")\n",
    "            else:\n",
    "                print(f\"  - {item}\")\n",
    "\n",
    "# Calculate overall quality score\n",
    "total_issues = sum(len(issues) for issues in quality_issues.values())\n",
    "quality_score = max(0, 100 - (total_issues / processed * 100))\n",
    "\n",
    "print(f\"\\nOverall Dataset Quality Score: {quality_score:.1f}/100\")\n",
    "\n",
    "if quality_score >= 90:\n",
    "    print(\"‚úÖ Excellent dataset quality!\")\n",
    "elif quality_score >= 80:\n",
    "    print(\"‚úÖ Good dataset quality.\")\n",
    "elif quality_score >= 70:\n",
    "    print(\"‚ö†Ô∏è  Acceptable dataset quality with minor issues.\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset quality needs improvement.\")\n",
    "\n",
    "# Recommendations\n",
    "print(\"\\nRecommendations:\")\n",
    "recommendations = []\n",
    "\n",
    "if quality_issues['corrupted_images']:\n",
    "    recommendations.append(\"- Remove or fix corrupted images before training\")\n",
    "\n",
    "if quality_issues['extremely_small_images']:\n",
    "    recommendations.append(\"- Consider upsampling or removing very small images\")\n",
    "\n",
    "if quality_issues['unusual_aspect_ratios']:\n",
    "    recommendations.append(\"- Review images with unusual aspect ratios for relevance\")\n",
    "\n",
    "if quality_issues['very_dark_images'] or quality_issues['very_bright_images']:\n",
    "    recommendations.append(\"- Consider brightness normalization during preprocessing\")\n",
    "\n",
    "if quality_issues['grayscale_images']:\n",
    "    recommendations.append(\"- Ensure grayscale images are properly converted to RGB\")\n",
    "\n",
    "if not recommendations:\n",
    "    recommendations.append(\"- Dataset appears to be in good condition for training\")\n",
    "\n",
    "for rec in recommendations:\n",
    "    print(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Loading Performance Test\n",
    "\n",
    "Test the performance of data loading with different configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import time\nfrom torch.utils.data import DataLoader\n\ndef test_dataloader_performance(data_dir, image_sizes=[32, 64], batch_sizes=[16, 32, 64], num_workers_list=[0, 2, 4]):\n    \"\"\"Test data loading performance with different configurations\"\"\"\n    \n    print(\"Testing DataLoader Performance...\")\n    print(\"=\" * 50)\n    \n    results = []\n    \n    for image_size in image_sizes:\n        for batch_size in batch_sizes:\n            for num_workers in num_workers_list:\n                try:\n                    # Create dataset\n                    dataset = SportsDataset(\n                        root_dir=data_dir,\n                        split='train',\n                        image_size=image_size,\n                        augment=True\n                    )\n                    \n                    # Create dataloader\n                    dataloader = DataLoader(\n                        dataset,\n                        batch_size=batch_size,\n                        shuffle=True,\n                        num_workers=num_workers,\n                        pin_memory=True\n                    )\n                    \n                    # Time loading first few batches\n                    start_time = time.time()\n                    batch_count = 0\n                    max_batches = min(10, len(dataloader))  # Test first 10 batches\n                    \n                    for batch_idx, (images, labels) in enumerate(dataloader):\n                        if batch_idx >= max_batches:\n                            break\n                        batch_count += 1\n                        \n                        # Ensure data is actually loaded\n                        _ = images.mean()\n                    \n                    end_time = time.time()\n                    total_time = end_time - start_time\n                    time_per_batch = total_time / batch_count if batch_count > 0 else float('inf')\n                    \n                    result = {\n                        'image_size': image_size,\n                        'batch_size': batch_size,\n                        'num_workers': num_workers,\n                        'total_time': total_time,\n                        'time_per_batch': time_per_batch,\n                        'batches_tested': batch_count\n                    }\n                    \n                    results.append(result)\n                    \n                    print(f\"Size: {image_size:2d}, Batch: {batch_size:2d}, Workers: {num_workers}, \"\n                          f\"Time/batch: {time_per_batch:.3f}s\")\n                    \n                except Exception as e:\n                    print(f\"Error with config (size:{image_size}, batch:{batch_size}, workers:{num_workers}): {e}\")\n    \n    return results\n\n# Test different configurations\nperf_results = test_dataloader_performance(DATA_DIR)\n\n# Analyze results\nif perf_results:\n    # Convert to DataFrame for easier analysis\n    df_results = pd.DataFrame(perf_results)\n    \n    print(\"\\nPerformance Analysis:\")\n    print(\"-\" * 30)\n    \n    # Best configuration overall\n    best_config = df_results.loc[df_results['time_per_batch'].idxmin()]\n    print(f\"\\nBest overall configuration:\")\n    print(f\"  Image size: {int(best_config['image_size'])}\")\n    print(f\"  Batch size: {int(best_config['batch_size'])}\")\n    print(f\"  Num workers: {int(best_config['num_workers'])}\")\n    print(f\"  Time per batch: {best_config['time_per_batch']:.3f}s\")\n    \n    # Best for each image size\n    print(\"\\nBest configuration for each image size:\")\n    for size in sorted(df_results['image_size'].unique()):\n        size_data = df_results[df_results['image_size'] == size]\n        best_for_size = size_data.loc[size_data['time_per_batch'].idxmin()]\n        print(f\"  {int(size)}x{int(size)}: batch={int(best_for_size['batch_size'])}, \"\n              f\"workers={int(best_for_size['num_workers'])}, \"\n              f\"time={best_for_size['time_per_batch']:.3f}s/batch\")\n    \n    # Visualize performance results\n    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n    \n    # Performance by batch size\n    for size in sorted(df_results['image_size'].unique()):\n        size_data = df_results[df_results['image_size'] == size]\n        batch_performance = size_data.groupby('batch_size')['time_per_batch'].min()\n        axes[0].plot(batch_performance.index, batch_performance.values, \n                    marker='o', label=f'{int(size)}x{int(size)}')\n    \n    axes[0].set_title('Loading Time vs Batch Size', fontweight='bold')\n    axes[0].set_xlabel('Batch Size')\n    axes[0].set_ylabel('Time per Batch (seconds)')\n    axes[0].legend()\n    axes[0].grid(True, alpha=0.3)\n    \n    # Performance by number of workers\n    for size in sorted(df_results['image_size'].unique()):\n        size_data = df_results[df_results['image_size'] == size]\n        worker_performance = size_data.groupby('num_workers')['time_per_batch'].min()\n        axes[1].plot(worker_performance.index, worker_performance.values, \n                    marker='s', label=f'{int(size)}x{int(size)}')\n    \n    axes[1].set_title('Loading Time vs Number of Workers', fontweight='bold')\n    axes[1].set_xlabel('Number of Workers')\n    axes[1].set_ylabel('Time per Batch (seconds)')\n    axes[1].legend()\n    axes[1].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Recommendations\n",
    "\n",
    "Summary of dataset analysis and recommendations for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATASET EXPLORATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Dataset overview summary\n",
    "print(\"\\nüìä DATASET OVERVIEW:\")\n",
    "print(f\"   ‚Ä¢ Total images: {dataset_stats['total_images']:,}\")\n",
    "print(f\"   ‚Ä¢ Number of classes: {len(dataset_stats['classes'])}\")\n",
    "print(f\"   ‚Ä¢ Classes: {', '.join(dataset_stats['classes'])}\")\n",
    "\n",
    "if 'train' in dataset_stats['splits']:\n",
    "    train_total = dataset_stats['splits']['train']['total_images']\n",
    "    print(f\"   ‚Ä¢ Training images: {train_total:,}\")\n",
    "\n",
    "if 'valid' in dataset_stats['splits']:\n",
    "    valid_total = dataset_stats['splits']['valid']['total_images']\n",
    "    print(f\"   ‚Ä¢ Validation images: {valid_total:,}\")\n",
    "    \n",
    "    if 'train' in dataset_stats['splits']:\n",
    "        split_ratio = train_total / valid_total if valid_total > 0 else float('inf')\n",
    "        print(f\"   ‚Ä¢ Train/Val split ratio: {split_ratio:.1f}:1\")\n",
    "\n",
    "# Class balance summary\n",
    "print(\"\\n‚öñÔ∏è  CLASS BALANCE:\")\n",
    "if 'train' in dataset_stats['splits']:\n",
    "    train_dist = dataset_stats['splits']['train']['class_distribution']\n",
    "    train_counts = list(train_dist.values())\n",
    "    if train_counts:\n",
    "        balance_ratio = min(train_counts) / max(train_counts)\n",
    "        cv = np.std(train_counts) / np.mean(train_counts)\n",
    "        print(f\"   ‚Ä¢ Balance ratio (min/max): {balance_ratio:.3f}\")\n",
    "        print(f\"   ‚Ä¢ Coefficient of variation: {cv:.3f}\")\n",
    "        \n",
    "        if balance_ratio > 0.8:\n",
    "            print(\"   ‚úÖ Well-balanced dataset\")\n",
    "        elif balance_ratio > 0.6:\n",
    "            print(\"   ‚ö†Ô∏è  Moderately imbalanced - consider class weighting\")\n",
    "        else:\n",
    "            print(\"   ‚ùå Highly imbalanced - consider resampling techniques\")\n",
    "\n",
    "# Image properties summary\n",
    "print(\"\\nüñºÔ∏è  IMAGE PROPERTIES:\")\n",
    "if img_properties['dimensions']:\n",
    "    widths, heights = zip(*img_properties['dimensions'])\n",
    "    print(f\"   ‚Ä¢ Average dimensions: {np.mean(widths):.0f}x{np.mean(heights):.0f} pixels\")\n",
    "    print(f\"   ‚Ä¢ Size range: {min(widths)}x{min(heights)} to {max(widths)}x{max(heights)}\")\n",
    "\n",
    "if img_properties['aspect_ratios']:\n",
    "    avg_ratio = np.mean(img_properties['aspect_ratios'])\n",
    "    print(f\"   ‚Ä¢ Average aspect ratio: {avg_ratio:.2f}\")\n",
    "\n",
    "if img_properties['file_sizes']:\n",
    "    avg_size_kb = np.mean(img_properties['file_sizes']) / 1024\n",
    "    print(f\"   ‚Ä¢ Average file size: {avg_size_kb:.1f} KB\")\n",
    "\n",
    "# Quality assessment summary\n",
    "print(\"\\nüîç QUALITY ASSESSMENT:\")\n",
    "total_issues = sum(len(issues) for issues in quality_issues.values())\n",
    "quality_score = max(0, 100 - (total_issues / processed * 100))\n",
    "print(f\"   ‚Ä¢ Quality score: {quality_score:.1f}/100\")\n",
    "print(f\"   ‚Ä¢ Issues found: {total_issues} out of {processed} sampled images\")\n",
    "\n",
    "major_issues = [\n",
    "    ('corrupted_images', 'Corrupted images'),\n",
    "    ('extremely_small_images', 'Very small images'),\n",
    "    ('extremely_large_images', 'Very large images')\n",
    "]\n",
    "\n",
    "for issue_key, issue_name in major_issues:\n",
    "    if quality_issues[issue_key]:\n",
    "        print(f\"   ‚ö†Ô∏è  {issue_name}: {len(quality_issues[issue_key])}\")\n",
    "\n",
    "# Performance summary\n",
    "print(\"\\n‚ö° PERFORMANCE OPTIMIZATION:\")\n",
    "if perf_results:\n",
    "    df_results = pd.DataFrame(perf_results)\n",
    "    best_config = df_results.loc[df_results['time_per_batch'].idxmin()]\n",
    "    print(f\"   ‚Ä¢ Optimal batch size: {int(best_config['batch_size'])}\")\n",
    "    print(f\"   ‚Ä¢ Optimal workers: {int(best_config['num_workers'])}\")\n",
    "    print(f\"   ‚Ä¢ Loading time: {best_config['time_per_batch']:.3f}s per batch\")\n",
    "\n",
    "# Training recommendations\n",
    "print(\"\\nüéØ TRAINING RECOMMENDATIONS:\")\n",
    "print(\"\\n   Data Preprocessing:\")\n",
    "print(\"   ‚Ä¢ Use data augmentation (rotation, flip, color jitter) ‚úÖ\")\n",
    "print(\"   ‚Ä¢ Apply normalization with ImageNet statistics ‚úÖ\")\n",
    "print(\"   ‚Ä¢ Consider image size: 32x32 for quick experiments, 64x64+ for better accuracy\")\n",
    "\n",
    "print(\"\\n   Training Strategy:\")\n",
    "if 'train' in dataset_stats['splits'] and 'valid' in dataset_stats['splits']:\n",
    "    train_dist = dataset_stats['splits']['train']['class_distribution']\n",
    "    train_counts = list(train_dist.values())\n",
    "    if train_counts:\n",
    "        balance_ratio = min(train_counts) / max(train_counts)\n",
    "        if balance_ratio < 0.8:\n",
    "            print(\"   ‚Ä¢ Consider class weighting due to imbalance\")\n",
    "        print(\"   ‚Ä¢ Use cross-entropy loss for multi-class classification\")\n",
    "        print(\"   ‚Ä¢ Monitor both accuracy and per-class F1 scores\")\n",
    "\n",
    "print(\"\\n   Model Architecture:\")\n",
    "print(\"   ‚Ä¢ Start with SimpleCNN for baseline\")\n",
    "print(\"   ‚Ä¢ Try ResNet for better feature extraction\")\n",
    "print(\"   ‚Ä¢ Consider dropout for regularization\")\n",
    "\n",
    "print(\"\\n   Hyperparameters:\")\n",
    "if perf_results:\n",
    "    df_results = pd.DataFrame(perf_results)\n",
    "    best_config = df_results.loc[df_results['time_per_batch'].idxmin()]\n",
    "    print(f\"   ‚Ä¢ Batch size: {int(best_config['batch_size'])} (based on performance test)\")\n",
    "    print(f\"   ‚Ä¢ Num workers: {int(best_config['num_workers'])} (based on performance test)\")\n",
    "print(\"   ‚Ä¢ Learning rate: Start with 1e-3, use scheduler\")\n",
    "print(\"   ‚Ä¢ Epochs: 50-100 with early stopping\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Dataset exploration complete! Ready for model training.\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
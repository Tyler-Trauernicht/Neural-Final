{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE4745 Neural Network Final Project - Master Notebook (FIXED)\n",
    "## Defending LSU's Sports AI - Complete Implementation\n",
    "\n",
    "**Problems Covered:**\n",
    "- Problem A: Sports Image Classification (220 pts)\n",
    "- Problem B: Adversarial Attacks (100 pts)\n",
    "- Problem C: Model Compression (100 pts)\n",
    "\n",
    "**â±ï¸ Estimated Runtime:** 2-3 hours (depending on epochs)\n",
    "\n",
    "**âœ… This version has all fixes applied for Google Colab!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Prerequisites\n",
    "\n",
    "**Before running this notebook:**\n",
    "\n",
    "1. âœ… Upload `EE4745-project-data-to-release` folder to your Google Drive\n",
    "2. âœ… Make sure it's at: `/MyDrive/EE4745-project-data-to-release/`\n",
    "3. âœ… Verify it has `train/` and `valid/` folders inside\n",
    "\n",
    "**Then just click Runtime â†’ Run all!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ STEP 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check PyTorch and hardware availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"Running on CPU (as designed for this project)\")\n",
    "\n",
    "print(\"\\nâœ… Environment check complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ STEP 2: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive to access dataset\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\nâœ… Google Drive mounted successfully!\")\n",
    "print(\"\\nğŸ“‚ Your dataset should be at:\")\n",
    "print(\"   /content/drive/MyDrive/EE4745-project-data-to-release/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ STEP 3: Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository from GitHub\n",
    "import os\n",
    "\n",
    "# Remove if already exists\n",
    "!rm -rf Neural-Final\n",
    "\n",
    "# Clone fresh copy\n",
    "!git clone https://github.com/Tyler-Trauernicht/Neural-Final.git\n",
    "\n",
    "# Change to repository directory\n",
    "%cd Neural-Final\n",
    "\n",
    "# Verify we're in the right place\n",
    "!pwd\n",
    "print(\"\\nâœ… Repository cloned successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”— STEP 4: Fix Dataset Link (CRITICAL FIX!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL: Remove broken Mac symlink and create Colab-compatible link\n",
    "print(\"ğŸ”§ Fixing dataset symlink for Google Colab...\\n\")\n",
    "\n",
    "# Remove the broken symlink from the repository\n",
    "!rm -f data\n",
    "\n",
    "# Create new symlink to Google Drive dataset\n",
    "!ln -sf /content/drive/MyDrive/EE4745-project-data-to-release data\n",
    "\n",
    "# Verify the fix worked\n",
    "print(\"\\nâœ… Verifying dataset access...\")\n",
    "print(\"\\nğŸ“‚ Dataset structure:\")\n",
    "!ls -la data/\n",
    "\n",
    "print(\"\\nğŸ“‚ Training classes:\")\n",
    "!ls data/train/\n",
    "\n",
    "print(\"\\nğŸ“‚ Validation classes:\")\n",
    "!ls data/valid/\n",
    "\n",
    "print(\"\\nğŸ“Š Image counts:\")\n",
    "!echo \"  Training images: $(find data/train -name '*.jpg' | wc -l)\"\n",
    "!echo \"  Validation images: $(find data/valid -name '*.jpg' | wc -l)\"\n",
    "\n",
    "# Check if successful\n",
    "if os.path.exists('data/train') and os.path.exists('data/valid'):\n",
    "    print(\"\\nâœ… Dataset successfully linked!\")\n",
    "else:\n",
    "    print(\"\\nâŒ ERROR: Dataset not found!\")\n",
    "    print(\"\\nPlease check:\")\n",
    "    print(\"1. Dataset is uploaded to Google Drive\")\n",
    "    print(\"2. Path is correct: /content/drive/MyDrive/EE4745-project-data-to-release/\")\n",
    "    print(\"3. Dataset has 'train' and 'valid' folders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š STEP 5: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "print(\"ğŸ“¦ Installing dependencies...\\n\")\n",
    "\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q numpy pandas matplotlib seaborn\n",
    "!pip install -q tensorboard scikit-learn tqdm\n",
    "!pip install -q Pillow opencv-python\n",
    "\n",
    "print(\"\\nâœ… All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… STEP 6: Verify Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset loading with actual code\n",
    "import sys\n",
    "sys.path.append('/content/Neural-Final')\n",
    "\n",
    "from src.dataset.sports_dataset import SportsDataset, get_dataloaders\n",
    "\n",
    "print(\"ğŸ§ª Testing dataset loading...\\n\")\n",
    "\n",
    "try:\n",
    "    train_loader, val_loader, num_classes = get_dataloaders(\n",
    "        data_dir='data',\n",
    "        batch_size=32,\n",
    "        image_size=32,\n",
    "        num_workers=2\n",
    "    )\n",
    "    \n",
    "    print(\"\\nâœ… Dataset loaded successfully!\")\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    print(f\"Classes: {SportsDataset.CLASSES}\")\n",
    "    \n",
    "    # Test loading a batch\n",
    "    images, labels = next(iter(train_loader))\n",
    "    print(f\"\\nBatch shape: {images.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ‰ ALL SETUP COMPLETE! READY TO TRAIN!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Error: {e}\")\n",
    "    print(\"\\nâš ï¸ Setup failed. Please check the error above.\")\n",
    "    print(\"\\nCommon fixes:\")\n",
    "    print(\"1. Re-run the 'Fix Dataset Link' cell above\")\n",
    "    print(\"2. Verify dataset is in Google Drive\")\n",
    "    print(\"3. Check dataset folder structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ğŸ¯ PROBLEM A: Sports Image Classification\n",
    "---\n",
    "\n",
    "**This section will:**\n",
    "- Train SimpleCNN and ResNetSmall models\n",
    "- Generate interpretability analysis\n",
    "- Create performance visualizations\n",
    "\n",
    "**Estimated time:** 60-90 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Train SimpleCNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SimpleCNN model\n",
    "# Adjust --epochs for faster training: use 5-10 for testing, 20-50 for full training\n",
    "\n",
    "print(\"ğŸ‹ï¸ Training SimpleCNN...\\n\")\n",
    "print(\"\" + \"=\"*60)\n",
    "\n",
    "!python train_problem_a.py \\\n",
    "    --model SimpleCNN \\\n",
    "    --epochs 20 \\\n",
    "    --batch_size 32 \\\n",
    "    --learning_rate 0.001 \\\n",
    "    --device cpu \\\n",
    "    --image_size 32\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… SimpleCNN training complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Train ResNetSmall Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ResNetSmall model\n",
    "# ResNet has more parameters so may take longer\n",
    "\n",
    "print(\"ğŸ‹ï¸ Training ResNetSmall...\\n\")\n",
    "print(\"\" + \"=\"*60)\n",
    "\n",
    "!python train_problem_a.py \\\n",
    "    --model ResNetSmall \\\n",
    "    --epochs 20 \\\n",
    "    --batch_size 16 \\\n",
    "    --learning_rate 0.001 \\\n",
    "    --device cpu \\\n",
    "    --image_size 32\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… ResNetSmall training complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Generate Interpretability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Saliency Maps and Grad-CAM visualizations\n",
    "print(\"ğŸ” Generating interpretability analysis...\\n\")\n",
    "\n",
    "!python train_problem_a.py \\\n",
    "    --model both \\\n",
    "    --skip_training \\\n",
    "    --interpretability_samples 15\n",
    "\n",
    "print(\"\\nâœ… Interpretability analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ View Problem A Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“Š PROBLEM A RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Display training curves\n",
    "print(\"\\nğŸ“ˆ Training Curves:\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for idx, model_name in enumerate(['SimpleCNN', 'ResNetSmall']):\n",
    "    curve_path = f'results/problem_a/training_curves/{model_name}_training_curves.png'\n",
    "    if os.path.exists(curve_path):\n",
    "        img = Image.open(curve_path)\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].axis('off')\n",
    "        axes[idx].set_title(model_name, fontsize=14)\n",
    "    else:\n",
    "        axes[idx].text(0.5, 0.5, 'Not found', ha='center', va='center')\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display confusion matrices\n",
    "print(\"\\nğŸ¯ Confusion Matrices:\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "for idx, model_name in enumerate(['SimpleCNN', 'ResNetSmall']):\n",
    "    cm_path = f'results/problem_a/evaluation/{model_name}_confusion_matrix.png'\n",
    "    if os.path.exists(cm_path):\n",
    "        img = Image.open(cm_path)\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].axis('off')\n",
    "        axes[idx].set_title(f'{model_name} Confusion Matrix', fontsize=14)\n",
    "    else:\n",
    "        axes[idx].text(0.5, 0.5, 'Not found', ha='center', va='center')\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display sample interpretability results\n",
    "print(\"\\nğŸ” Sample Interpretability Results:\")\n",
    "interp_dir = 'results/problem_a/interpretability/SimpleCNN_saliency/'\n",
    "if os.path.exists(interp_dir):\n",
    "    sample_files = [f for f in sorted(os.listdir(interp_dir)) if f.endswith('.png')][:4]\n",
    "    if sample_files:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "        for idx, fname in enumerate(sample_files):\n",
    "            img = Image.open(os.path.join(interp_dir, fname))\n",
    "            axes[idx//2, idx%2].imshow(img)\n",
    "            axes[idx//2, idx%2].axis('off')\n",
    "            axes[idx//2, idx%2].set_title(fname, fontsize=10)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"\\nâœ… Problem A complete! Check results/problem_a/ for all outputs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ğŸ›¡ï¸ PROBLEM B: Adversarial Attacks\n",
    "---\n",
    "\n",
    "**This section will:**\n",
    "- Generate adversarial examples using FGSM and PGD\n",
    "- Test transferability between models\n",
    "- Create attack visualizations\n",
    "\n",
    "**Estimated time:** 20-40 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš”ï¸ Generate Adversarial Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comprehensive adversarial attack analysis\n",
    "# Note: Using hyphens not underscores in arguments!\n",
    "\n",
    "print(\"âš”ï¸ Generating adversarial examples...\\n\")\n",
    "print(\"\" + \"=\"*60)\n",
    "\n",
    "!python attack_problem_b.py \\\n",
    "    --data-dir data \\\n",
    "    --num-samples 20 \\\n",
    "    --device cpu\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Adversarial attack generation complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ Additional Attack Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate additional samples for comprehensive analysis\n",
    "print(\"ğŸ”„ Running additional attack analysis...\\n\")\n",
    "\n",
    "!python attack_problem_b.py \\\n",
    "    --data-dir data \\\n",
    "    --num-samples 10 \\\n",
    "    --device cpu\n",
    "\n",
    "print(\"\\nâœ… Additional analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š View Problem B Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display adversarial attack results\n",
    "import json\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ›¡ï¸ PROBLEM B RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check for results files\n",
    "prob_b_dir = 'results/problem_b/'\n",
    "if os.path.exists(prob_b_dir):\n",
    "    print(f\"\\nğŸ“ Results saved in: {prob_b_dir}\")\n",
    "    print(\"\\nğŸ“‚ Contents:\")\n",
    "    !ls -lh {prob_b_dir}\n",
    "    \n",
    "    # Display attack statistics if available\n",
    "    stats_file = os.path.join(prob_b_dir, 'attack_statistics.json')\n",
    "    if os.path.exists(stats_file):\n",
    "        with open(stats_file, 'r') as f:\n",
    "            stats = json.load(f)\n",
    "        print(\"\\nğŸ“Š Attack Statistics:\")\n",
    "        print(json.dumps(stats, indent=2))\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ Statistics file not found (may be saved with different name)\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Results directory not found.\")\n",
    "    print(\"Attack script may have encountered errors.\")\n",
    "\n",
    "print(\"\\nâœ… Problem B complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# âš¡ PROBLEM C: Model Compression\n",
    "---\n",
    "\n",
    "**This section will:**\n",
    "- Apply unstructured pruning at multiple sparsity levels\n",
    "- Fine-tune pruned models\n",
    "- Measure performance trade-offs\n",
    "\n",
    "**Estimated time:** 30-60 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ‚ï¸ Apply Unstructured Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply pruning at multiple sparsity levels\n",
    "# The script has sensible defaults built-in\n",
    "\n",
    "print(\"âœ‚ï¸ Applying unstructured pruning...\\n\")\n",
    "print(\"\" + \"=\"*60)\n",
    "\n",
    "!python prune_problem_c.py\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Model pruning complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ View Problem C Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display pruning results and analysis\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"âš¡ PROBLEM C RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "prob_c_dir = 'results/problem_c/'\n",
    "if os.path.exists(prob_c_dir):\n",
    "    print(f\"\\nğŸ“ Results saved in: {prob_c_dir}\")\n",
    "    print(\"\\nğŸ“‚ Contents:\")\n",
    "    !ls -lh {prob_c_dir}\n",
    "    \n",
    "    # Display pruning analysis plots if available\n",
    "    analysis_file = os.path.join(prob_c_dir, 'demo_pruning_analysis.png')\n",
    "    if os.path.exists(analysis_file):\n",
    "        print(\"\\nğŸ“Š Pruning Analysis:\")\n",
    "        img = Image.open(analysis_file)\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title('Pruning Trade-off Analysis', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Display results table if available\n",
    "    results_csv = os.path.join(prob_c_dir, 'demo_pruning_results.csv')\n",
    "    if os.path.exists(results_csv):\n",
    "        print(\"\\nğŸ“Š Pruning Results Table:\")\n",
    "        df = pd.read_csv(results_csv)\n",
    "        print(df.to_string(index=False))\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ Results table not found\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Results directory not found.\")\n",
    "    print(\"Pruning script may have encountered errors.\")\n",
    "\n",
    "print(\"\\nâœ… Problem C complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ğŸ“Š FINAL: Comprehensive Results Compilation\n",
    "---\n",
    "\n",
    "**This section will:**\n",
    "- Compile all experimental results\n",
    "- Generate master performance dashboard\n",
    "- Create executive summary\n",
    "\n",
    "**Estimated time:** 10 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Generate Master Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all results into final analysis\n",
    "print(\"ğŸ“Š Compiling final results...\\n\")\n",
    "print(\"\" + \"=\"*60)\n",
    "\n",
    "!python results/final/run_final_analysis.py\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Final analysis complete!\")\n",
    "print(\"ğŸ“ All results compiled in: results/final/\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š View Master Performance Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the master performance dashboard\n",
    "print(\"ğŸ¯ Master Performance Dashboard:\\n\")\n",
    "\n",
    "dashboard_path = 'results/final/figures/master_performance_dashboard.png'\n",
    "if os.path.exists(dashboard_path):\n",
    "    img = Image.open(dashboard_path)\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Complete Project Performance Dashboard', fontsize=18, pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"âš ï¸ Dashboard not found.\")\n",
    "    print(\"Results compilation may have used template data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ View Executive Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display executive summary\n",
    "summary_path = 'results/final/summary/executive_summary.md'\n",
    "if os.path.exists(summary_path):\n",
    "    print(\"=\"*80)\n",
    "    print(\"ğŸ“„ EXECUTIVE SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    with open(summary_path, 'r') as f:\n",
    "        print(f.read())\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"âš ï¸ Executive summary not found.\")\n",
    "\n",
    "print(\"\\nâœ… All analyses complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ğŸ’¾ DOWNLOAD ALL RESULTS\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¥ Create Results Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive ZIP archive of all results\n",
    "from datetime import datetime\n",
    "\n",
    "# Create timestamp for filename\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "archive_name = f'EE4745_Neural_Final_Results_{timestamp}'\n",
    "\n",
    "print(\"ğŸ“¦ Creating results archive...\")\n",
    "print(f\"Archive name: {archive_name}.zip\\n\")\n",
    "\n",
    "# Create ZIP of all results\n",
    "!zip -r {archive_name}.zip \\\n",
    "    results/ \\\n",
    "    checkpoints/ \\\n",
    "    logs/ \\\n",
    "    -x \"*__pycache__*\" \"*.pyc\" \\\n",
    "    > /dev/null 2>&1\n",
    "\n",
    "print(f\"\\nâœ… Archive created: {archive_name}.zip\")\n",
    "print(\"\\nğŸ“Š Archive size:\")\n",
    "!ls -lh {archive_name}.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¥ Download Results to Your Computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the results archive to your local machine\n",
    "from google.colab import files\n",
    "import glob\n",
    "\n",
    "# Find the archive file\n",
    "archive_files = glob.glob('EE4745_Neural_Final_Results_*.zip')\n",
    "\n",
    "if archive_files:\n",
    "    archive_file = archive_files[0]\n",
    "    print(f\"ğŸ“¥ Downloading: {archive_file}\")\n",
    "    print(\"â³ This may take a few minutes...\\n\")\n",
    "    \n",
    "    files.download(archive_file)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… DOWNLOAD COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nğŸ“¦ Your archive contains:\")\n",
    "    print(\"  â€¢ results/       - All experimental results and visualizations\")\n",
    "    print(\"  â€¢ checkpoints/   - All trained and pruned model files\")\n",
    "    print(\"  â€¢ logs/          - TensorBoard training logs\")\n",
    "    print(\"\\nğŸ’¡ Extract the ZIP file on your computer to access all materials!\")\n",
    "else:\n",
    "    print(\"âŒ No archive found. Please run the 'Create Results Archive' cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ğŸ‰ COMPLETION SUMMARY\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final completion summary\n",
    "print(\"\")\n",
    "print(\"=\"*80)\n",
    "print(\"\" + \" \"*15 + \"ğŸ“ EE4745 NEURAL NETWORK FINAL PROJECT\")\n",
    "print(\"\" + \" \"*25 + \"COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*80)\n",
    "print(\"âœ… PROBLEM A: Sports Image Classification - COMPLETE\")\n",
    "print(\"â”€\"*80)\n",
    "print(\"   âœ“ SimpleCNN trained and evaluated\")\n",
    "print(\"   âœ“ ResNetSmall trained and evaluated\")\n",
    "print(\"   âœ“ Interpretability analysis generated (Saliency + Grad-CAM)\")\n",
    "print(\"   âœ“ Model comparison completed\")\n",
    "print(\"   âœ“ Training curves and confusion matrices created\")\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*80)\n",
    "print(\"âœ… PROBLEM B: Adversarial Attacks - COMPLETE\")\n",
    "print(\"â”€\"*80)\n",
    "print(\"   âœ“ FGSM and PGD attacks implemented\")\n",
    "print(\"   âœ“ Targeted and untargeted attacks executed\")\n",
    "print(\"   âœ“ Adversarial examples generated\")\n",
    "print(\"   âœ“ Transferability analysis performed\")\n",
    "print(\"   âœ“ Attack visualizations created\")\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*80)\n",
    "print(\"âœ… PROBLEM C: Model Compression - COMPLETE\")\n",
    "print(\"â”€\"*80)\n",
    "print(\"   âœ“ Unstructured pruning applied (20%, 50%, 80%)\")\n",
    "print(\"   âœ“ Models fine-tuned after pruning\")\n",
    "print(\"   âœ“ Performance analysis completed\")\n",
    "print(\"   âœ“ Trade-off visualizations created\")\n",
    "print(\"   âœ“ Efficiency improvements measured\")\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*80)\n",
    "print(\"âœ… FINAL RESULTS - COMPLETE\")\n",
    "print(\"â”€\"*80)\n",
    "print(\"   âœ“ Master performance dashboard generated\")\n",
    "print(\"   âœ“ Executive summary created\")\n",
    "print(\"   âœ“ All results compiled and organized\")\n",
    "print(\"   âœ“ Results archive ready for download\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“¦ DELIVERABLES READY FOR SUBMISSION\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n1. âœ… Source code (all .py files and notebooks)\")\n",
    "print(\"2. âœ… Trained model checkpoints (.pt files)\")\n",
    "print(\"3. âœ… Experimental results and visualizations\")\n",
    "print(\"4. âœ… Analysis reports and summaries\")\n",
    "print(\"5. âœ… Performance comparison tables\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ¯ NEXT STEPS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n1. Extract the downloaded ZIP file\")\n",
    "print(\"2. Review all generated results and visualizations\")\n",
    "print(\"3. Write your final report using the materials\")\n",
    "print(\"4. Include figures from results/final/figures/\")\n",
    "print(\"5. Reference tables from results/final/tables/\")\n",
    "print(\"6. Use analysis from results/final/reports/\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\" + \" \"*20 + \"ğŸš€ Good luck with your submission!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
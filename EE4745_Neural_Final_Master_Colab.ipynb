{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE4745 Neural Network Final Project - Master Notebook\n",
    "## Defending LSU's Sports AI - Complete Implementation\n",
    "\n",
    "**Problems Covered:**\n",
    "- Problem A: Sports Image Classification (220 pts)\n",
    "- Problem B: Adversarial Attacks (100 pts)\n",
    "- Problem C: Model Compression (100 pts)\n",
    "\n",
    "**‚è±Ô∏è Estimated Runtime:** 2-3 hours (depending on epochs)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Setup Instructions\n",
    "\n",
    "**Before running this notebook, you need to:**\n",
    "\n",
    "1. **Upload the dataset to Google Drive** (recommended) or upload directly\n",
    "2. **Have your GitHub repository ready** (https://github.com/Tyler-Trauernicht/Neural-Final.git)\n",
    "\n",
    "**Dataset Location Options:**\n",
    "- Option A: Upload `EE4745-project-data-to-release.zip` to Google Drive\n",
    "- Option B: Upload dataset directly in the \"Upload Dataset\" cell below\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß STEP 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability (optional - project works on CPU)\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"Running on CPU (as designed for this project)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ STEP 2: Mount Google Drive (Option A - Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"‚úÖ Google Drive mounted successfully!\")\n",
    "print(\"\\nPlease ensure your dataset is at:\")\n",
    "print(\"  /content/drive/MyDrive/EE4745-project-data-to-release/\")\n",
    "print(\"  (with 'train' and 'valid' folders inside)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ STEP 3: Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository from GitHub\n",
    "!git clone https://github.com/Tyler-Trauernicht/Neural-Final.git\n",
    "%cd Neural-Final\n",
    "\n",
    "# Verify we're in the right directory\n",
    "!pwd\n",
    "!ls -la\n",
    "\n",
    "print(\"\\n‚úÖ Repository cloned successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö STEP 4: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q numpy pandas matplotlib seaborn\n",
    "!pip install -q tensorboard scikit-learn tqdm\n",
    "!pip install -q Pillow opencv-python\n",
    "\n",
    "print(\"‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîó STEP 5: Setup Dataset Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# OPTION A: If dataset is in Google Drive\n",
    "# Adjust this path to where YOUR dataset is located in Google Drive\n",
    "drive_dataset_path = '/content/drive/MyDrive/EE4745-project-data-to-release'\n",
    "\n",
    "# Create symbolic link\n",
    "if os.path.exists(drive_dataset_path):\n",
    "    !ln -s {drive_dataset_path} data\n",
    "    print(f\"‚úÖ Dataset linked from Google Drive: {drive_dataset_path}\")\n",
    "else:\n",
    "    print(f\"‚ùå Dataset not found at: {drive_dataset_path}\")\n",
    "    print(\"\\nPlease either:\")\n",
    "    print(\"1. Upload dataset to Google Drive at the path above, OR\")\n",
    "    print(\"2. Use OPTION B below to upload directly\")\n",
    "\n",
    "# Verify dataset structure\n",
    "if os.path.exists('data'):\n",
    "    print(\"\\nüìä Dataset structure:\")\n",
    "    !ls -la data/\n",
    "    print(\"\\nTraining classes:\")\n",
    "    !ls data/train/ 2>/dev/null || echo \"Train folder not found\"\n",
    "    print(\"\\nValidation classes:\")\n",
    "    !ls data/valid/ 2>/dev/null || echo \"Valid folder not found\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì§ OPTION B: Upload Dataset Directly (Alternative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY RUN THIS IF YOU DIDN'T USE GOOGLE DRIVE\n",
    "# This will prompt you to upload the dataset ZIP file\n",
    "\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "\n",
    "print(\"üì§ Upload your EE4745-project-data-to-release.zip file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Extract the uploaded ZIP\n",
    "for filename in uploaded.keys():\n",
    "    if filename.endswith('.zip'):\n",
    "        print(f\"\\nüì¶ Extracting {filename}...\")\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall('.')\n",
    "        \n",
    "        # Find the extracted folder and link it\n",
    "        !ln -s EE4745-project-data-to-release data\n",
    "        print(\"‚úÖ Dataset extracted and linked!\")\n",
    "\n",
    "# Verify\n",
    "!ls -la data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ STEP 6: Verify Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset loading\n",
    "import sys\n",
    "sys.path.append('/content/Neural-Final')\n",
    "\n",
    "from src.dataset.sports_dataset import SportsDataset, get_dataloaders\n",
    "\n",
    "print(\"üß™ Testing dataset loading...\\n\")\n",
    "\n",
    "try:\n",
    "    train_loader, val_loader, num_classes = get_dataloaders(\n",
    "        data_dir='data',\n",
    "        batch_size=32,\n",
    "        image_size=32,\n",
    "        num_workers=2\n",
    "    )\n",
    "    print(\"\\n‚úÖ Dataset loaded successfully!\")\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    print(f\"Classes: {SportsDataset.CLASSES}\")\n",
    "    \n",
    "    # Test loading a batch\n",
    "    images, labels = next(iter(train_loader))\n",
    "    print(f\"\\nBatch shape: {images.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(\"\\nüéâ All setup complete! Ready to train!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error: {e}\")\n",
    "    print(\"\\nPlease check:\")\n",
    "    print(\"1. Dataset is correctly uploaded/linked\")\n",
    "    print(\"2. Dataset has 'train' and 'valid' folders\")\n",
    "    print(\"3. Each folder contains the 10 sports class folders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üéØ PROBLEM A: Sports Image Classification\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Train SimpleCNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SimpleCNN with reduced epochs for faster training\n",
    "# Adjust --epochs based on your available time\n",
    "# For quick testing: --epochs 5\n",
    "# For full training: --epochs 50\n",
    "\n",
    "!python train_problem_a.py \\\n",
    "    --model SimpleCNN \\\n",
    "    --epochs 20 \\\n",
    "    --batch_size 32 \\\n",
    "    --learning_rate 0.001 \\\n",
    "    --device cpu \\\n",
    "    --image_size 32\n",
    "\n",
    "print(\"\\n‚úÖ SimpleCNN training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Train ResNetSmall Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ResNetSmall\n",
    "# Note: ResNet may take longer due to more parameters\n",
    "\n",
    "!python train_problem_a.py \\\n",
    "    --model ResNetSmall \\\n",
    "    --epochs 20 \\\n",
    "    --batch_size 16 \\\n",
    "    --learning_rate 0.001 \\\n",
    "    --device cpu \\\n",
    "    --image_size 32\n",
    "\n",
    "print(\"\\n‚úÖ ResNetSmall training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Generate Interpretability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Saliency Maps and Grad-CAM visualizations\n",
    "# This will analyze both correct and misclassified examples\n",
    "\n",
    "!python train_problem_a.py \\\n",
    "    --model both \\\n",
    "    --skip_training \\\n",
    "    --interpretability_samples 15 \\\n",
    "    --analyze_misclassifications\n",
    "\n",
    "print(\"\\n‚úÖ Interpretability analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà View Problem A Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Display training curves\n",
    "print(\"üìä Training Curves:\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for idx, model_name in enumerate(['SimpleCNN', 'ResNetSmall']):\n",
    "    curve_path = f'results/problem_a/training_curves/{model_name}_training_curves.png'\n",
    "    if os.path.exists(curve_path):\n",
    "        img = Image.open(curve_path)\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].axis('off')\n",
    "        axes[idx].set_title(model_name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display confusion matrices\n",
    "print(\"\\nüéØ Confusion Matrices:\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "for idx, model_name in enumerate(['SimpleCNN', 'ResNetSmall']):\n",
    "    cm_path = f'results/problem_a/evaluation/{model_name}_confusion_matrix.png'\n",
    "    if os.path.exists(cm_path):\n",
    "        img = Image.open(cm_path)\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].axis('off')\n",
    "        axes[idx].set_title(f'{model_name} Confusion Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display sample interpretability results\n",
    "print(\"\\nüîç Sample Interpretability Results:\")\n",
    "interp_dir = 'results/problem_a/interpretability/SimpleCNN_saliency/'\n",
    "if os.path.exists(interp_dir):\n",
    "    sample_files = sorted(os.listdir(interp_dir))[:4]\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "    for idx, fname in enumerate(sample_files):\n",
    "        if fname.endswith('.png'):\n",
    "            img = Image.open(os.path.join(interp_dir, fname))\n",
    "            axes[idx//2, idx%2].imshow(img)\n",
    "            axes[idx//2, idx%2].axis('off')\n",
    "            axes[idx//2, idx%2].set_title(fname)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Problem A complete! Check results/problem_a/ for all outputs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üõ°Ô∏è PROBLEM B: Adversarial Attacks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öîÔ∏è Generate Adversarial Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comprehensive adversarial attack analysis\n",
    "# This includes FGSM, PGD, targeted/untargeted attacks\n",
    "\n",
    "!python attack_problem_b.py \\\n",
    "    --data_dir data \\\n",
    "    --num_samples 20 \\\n",
    "    --device cpu\n",
    "\n",
    "print(\"\\n‚úÖ Adversarial attacks complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Transferability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze how attacks transfer between models\n",
    "\n",
    "!python attack_problem_b.py \\\n",
    "    --transferability_analysis \\\n",
    "    --detailed_interpretability\n",
    "\n",
    "print(\"\\n‚úÖ Transferability analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä View Problem B Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display adversarial attack results\n",
    "print(\"üõ°Ô∏è Problem B Results:\")\n",
    "\n",
    "# Check for results files\n",
    "prob_b_dir = 'results/problem_b/'\n",
    "if os.path.exists(prob_b_dir):\n",
    "    print(f\"\\nüìÅ Results saved in: {prob_b_dir}\")\n",
    "    !ls -la {prob_b_dir}\n",
    "    \n",
    "    # Display attack statistics if available\n",
    "    import json\n",
    "    stats_file = os.path.join(prob_b_dir, 'attack_statistics.json')\n",
    "    if os.path.exists(stats_file):\n",
    "        with open(stats_file, 'r') as f:\n",
    "            stats = json.load(f)\n",
    "        print(\"\\nüìä Attack Statistics:\")\n",
    "        print(json.dumps(stats, indent=2))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Results directory not found. Check if attacks ran successfully.\")\n",
    "\n",
    "print(\"\\n‚úÖ Problem B complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ‚ö° PROBLEM C: Model Compression\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è Apply Unstructured Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply pruning at 20%, 50%, 80% sparsity levels\n",
    "# This will prune both models and fine-tune them\n",
    "\n",
    "!python prune_problem_c.py \\\n",
    "    --sparsity_levels 0.2 0.5 0.8 \\\n",
    "    --fine_tune_epochs 10 \\\n",
    "    --fine_tune_lr 0.0001\n",
    "\n",
    "print(\"\\n‚úÖ Model pruning complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Comprehensive Pruning Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run complete analysis including performance and robustness evaluation\n",
    "\n",
    "!python complete_problem_c_analysis.py\n",
    "\n",
    "print(\"\\n‚úÖ Pruning analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà View Problem C Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display pruning results and analysis\n",
    "print(\"‚ö° Problem C Results:\")\n",
    "\n",
    "prob_c_dir = 'results/problem_c/'\n",
    "if os.path.exists(prob_c_dir):\n",
    "    print(f\"\\nüìÅ Results saved in: {prob_c_dir}\")\n",
    "    \n",
    "    # Display pruning analysis plots if available\n",
    "    analysis_file = os.path.join(prob_c_dir, 'demo_pruning_analysis.png')\n",
    "    if os.path.exists(analysis_file):\n",
    "        print(\"\\nüìä Pruning Analysis:\")\n",
    "        img = Image.open(analysis_file)\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title('Pruning Trade-off Analysis')\n",
    "        plt.show()\n",
    "    \n",
    "    # Display results table if available\n",
    "    import pandas as pd\n",
    "    results_csv = os.path.join(prob_c_dir, 'demo_pruning_results.csv')\n",
    "    if os.path.exists(results_csv):\n",
    "        print(\"\\nüìä Pruning Results Table:\")\n",
    "        df = pd.read_csv(results_csv)\n",
    "        print(df.to_string(index=False))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Results directory not found. Check if pruning ran successfully.\")\n",
    "\n",
    "print(\"\\n‚úÖ Problem C complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìä FINAL: Comprehensive Results Compilation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Generate Master Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all results into final analysis\n",
    "\n",
    "!python results/final/run_final_analysis.py\n",
    "\n",
    "print(\"\\n‚úÖ Final analysis complete!\")\n",
    "print(\"\\nüìÅ All results compiled in: results/final/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä View Master Performance Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the master performance dashboard\n",
    "\n",
    "dashboard_path = 'results/final/figures/master_performance_dashboard.png'\n",
    "if os.path.exists(dashboard_path):\n",
    "    print(\"üéØ Master Performance Dashboard:\")\n",
    "    img = Image.open(dashboard_path)\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Complete Project Performance Dashboard', fontsize=16)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Dashboard not found. Running analysis...\")\n",
    "    !python results/final/analysis/visualization_dashboard.py\n",
    "    if os.path.exists(dashboard_path):\n",
    "        img = Image.open(dashboard_path)\n",
    "        plt.figure(figsize=(20, 12))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã View Executive Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display executive summary\n",
    "\n",
    "summary_path = 'results/final/summary/executive_summary.md'\n",
    "if os.path.exists(summary_path):\n",
    "    print(\"üìÑ Executive Summary:\")\n",
    "    print(\"=\" * 80)\n",
    "    with open(summary_path, 'r') as f:\n",
    "        print(f.read())\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Executive summary not found.\")\n",
    "\n",
    "print(\"\\n‚úÖ All analyses complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üíæ DOWNLOAD ALL RESULTS\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Create Results Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive ZIP archive of all results\n",
    "\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Create timestamp for filename\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "archive_name = f'EE4745_Neural_Final_Results_{timestamp}'\n",
    "\n",
    "print(\"üì¶ Creating results archive...\\n\")\n",
    "\n",
    "# Create ZIP of all results\n",
    "!zip -r {archive_name}.zip \\\n",
    "    results/ \\\n",
    "    checkpoints/ \\\n",
    "    logs/ \\\n",
    "    notebooks/ \\\n",
    "    -x \"*__pycache__*\" \"*.pyc\"\n",
    "\n",
    "print(f\"\\n‚úÖ Archive created: {archive_name}.zip\")\n",
    "print(f\"üìä Archive size:\")\n",
    "!ls -lh {archive_name}.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the results archive to your local machine\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "# Get the archive filename\n",
    "import glob\n",
    "archive_files = glob.glob('EE4745_Neural_Final_Results_*.zip')\n",
    "\n",
    "if archive_files:\n",
    "    archive_file = archive_files[0]\n",
    "    print(f\"üì• Downloading: {archive_file}\")\n",
    "    print(\"‚è≥ This may take a few minutes depending on file size...\\n\")\n",
    "    \n",
    "    files.download(archive_file)\n",
    "    \n",
    "    print(\"\\n‚úÖ Download complete!\")\n",
    "    print(\"\\nüì¶ Your archive contains:\")\n",
    "    print(\"  - results/          All experimental results\")\n",
    "    print(\"  - checkpoints/      All trained model files\")\n",
    "    print(\"  - logs/            TensorBoard training logs\")\n",
    "    print(\"  - notebooks/       Jupyter analysis notebooks\")\n",
    "else:\n",
    "    print(\"‚ùå No archive found. Please run the archive creation cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÑ Download Individual Components (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download specific components if needed\n",
    "\n",
    "print(\"üì• Available for individual download:\\n\")\n",
    "\n",
    "# Option 1: Download only checkpoints\n",
    "# !zip -r checkpoints_only.zip checkpoints/\n",
    "# files.download('checkpoints_only.zip')\n",
    "\n",
    "# Option 2: Download only final results\n",
    "# !zip -r final_results.zip results/final/\n",
    "# files.download('final_results.zip')\n",
    "\n",
    "# Option 3: Download only notebooks\n",
    "# !zip -r notebooks.zip notebooks/\n",
    "# files.download('notebooks.zip')\n",
    "\n",
    "print(\"Uncomment the sections above to download specific components.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üéâ COMPLETION SUMMARY\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final completion summary\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üéì EE4745 NEURAL NETWORK FINAL PROJECT - COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n‚úÖ Problem A: Sports Image Classification - COMPLETE\")\n",
    "print(\"   - SimpleCNN trained and evaluated\")\n",
    "print(\"   - ResNetSmall trained and evaluated\")\n",
    "print(\"   - Interpretability analysis generated\")\n",
    "print(\"   - Model comparison completed\")\n",
    "\n",
    "print(\"\\n‚úÖ Problem B: Adversarial Attacks - COMPLETE\")\n",
    "print(\"   - FGSM and PGD attacks implemented\")\n",
    "print(\"   - Targeted and untargeted attacks executed\")\n",
    "print(\"   - Transferability analysis completed\")\n",
    "print(\"   - Attack visualizations generated\")\n",
    "\n",
    "print(\"\\n‚úÖ Problem C: Model Compression - COMPLETE\")\n",
    "print(\"   - Unstructured pruning applied (20%, 50%, 80%)\")\n",
    "print(\"   - Performance analysis completed\")\n",
    "print(\"   - Robustness evaluation finished\")\n",
    "print(\"   - Trade-off visualizations created\")\n",
    "\n",
    "print(\"\\n‚úÖ Final Results Compilation - COMPLETE\")\n",
    "print(\"   - Master performance dashboard generated\")\n",
    "print(\"   - Executive summary created\")\n",
    "print(\"   - All results compiled and ready\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üì¶ DELIVERABLES READY FOR SUBMISSION\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n1. ‚úÖ Source code (all .py files)\")\n",
    "print(\"2. ‚úÖ Trained model checkpoints\")\n",
    "print(\"3. ‚úÖ Experimental results and visualizations\")\n",
    "print(\"4. ‚úÖ Analysis reports and summaries\")\n",
    "print(\"5. ‚úÖ Jupyter notebooks\")\n",
    "\n",
    "print(\"\\nüì• Download the archive above to get all materials!\")\n",
    "print(\"\\nüéØ Next Step: Write your final report using the generated materials\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Good luck with your submission! üöÄ\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}